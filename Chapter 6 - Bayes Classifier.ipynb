{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Classifier and Bayes Risk\n",
    "\n",
    "_Kevin Siswandi_  \n",
    "**Fundamentals of Machine Learning**  \n",
    "June 2020  \n",
    "\n",
    "In this chapter, we will discuss the best possible classifier.\n",
    "\n",
    "## Bayes Theorem\n",
    "\n",
    "First let's review some basic concepts of probabilites. The product rule is\n",
    "\n",
    "$$ P(\\alpha \\cap \\beta) = P(\\alpha | \\beta) * P(\\beta) $$\n",
    "\n",
    "which is the foundation of Bayes Theorem:\n",
    "\n",
    "$$ P(\\alpha | \\beta) = \\frac{P(\\beta|\\alpha) P(\\alpha)}{P(\\beta)}$$\n",
    "\n",
    "This can be generalized to multiple events using the *chain rule of probability*:\n",
    "\n",
    "$$ P(\\alpha, \\beta, \\gamma) = P(\\alpha | \\beta, \\gamma) P(\\beta|\\gamma) P(\\gamma) = P(\\beta|\\alpha,\\gamma) P(\\alpha | \\gamma) P(\\gamma) = ...$$\n",
    "\n",
    "One consequence is that the expectation values also follow the rule\n",
    "\n",
    "$$ \\mathbb{E}_{\\alpha,\\beta}[.] = \\mathbb{E}_{\\alpha}\\mathbb{E}_{\\beta|\\alpha}[.] $$\n",
    "\n",
    "or in the case of independent sampling process:\n",
    "\n",
    "$$ \\mathbb{E}_{\\alpha,\\beta}[.] = \\mathbb{E}_{\\alpha}\\mathbb{E}_{\\beta}[.]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 Multivariate Distribution\n",
    "\n",
    "- Multivariate is just statistician's speak for \"multidimensional\"\n",
    "- Multivariate probability distribution, just like any other probability distribution, is normalized\n",
    "\n",
    "Say we have a discrete distribution of two random variables as shown below (which are obviously not independent)\n",
    "\n",
    "<img src=\"img/multivariate.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "The conditional probability $P(b|a = a_0)$ is conditioned on a specific value of $a = a_0$ and the function is really only dependent on $b$. The key thing to remember is that marginal distribution of a joint normal is normal, and the conditional distribution of a joint normal is normal. However, the joint distribution of normal marginal distributions is not necessarily normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Statistical decision theory\n",
    "\n",
    "Assume that we have a binary classification problem with set of class labels $Y \\in \\{1, 2\\}$. The questions that we would like to answer are:\n",
    "1. What does the best conceivable classifier look like?\n",
    "2. How good is it?\n",
    "\n",
    "In a nutshell: **Bayes classifier** is the proxy for the best possible classifier, and **Bayes risk** measures how good a Bayes classifier is. Bayes classifier is obtained by minimizing Bayes risk.\n",
    "\n",
    "Statistical model of classification gives a recipe for how to generate an observation $(x,y)$:\n",
    "\n",
    "<img src=\"img/stats-classification.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "In order for this task to make sense, the joint distribution of the features should be different for different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.1 Bayes Risk and Bayes Classifier\n",
    "\n",
    "First we define a loss function $L(y, \\hat{y})$, where $y$ is the true class and $\\hat{y}$ is the predicted class. Although some mistakes are costlier in real life, a simple loss is the 0-1 loss below:\n",
    "\n",
    "<img src=\"img/01loss.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Aim of classification: minimize the expected loss (i.e. **risk**) of the classifier $f$:\n",
    "\n",
    "$$ R(f) = \\mathbb{E}_X \\mathbb{E}_{Y|X} L(Y = y, f(X = x))$$\n",
    "\n",
    "where $Y$ and $X$ are random variables and $f$ is your deterministic classifier which could be kNN, RF, etc. By the definition of the expectation value, we can write (assuming continuous RV)\n",
    "\n",
    "$$ R(f) = \\int_x \\mathbb{E}_{Y|X} L(y, f(x)) p(x) dx $$\n",
    "\n",
    "Therefore, to minimize risk, we minimize $ \\mathbb{E}_{Y|X} L(y, f(x)) $ at every point $x$ in space. We can write this as a discrete summation over all possible class labels:\n",
    "\n",
    "<img src=\"img/bayes-risk.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Note that the second summation involves an indicator function that charges the loss only for the instances that are actually predicted by the classifier. Also, only wrong predictions incur loss. The final result is that, for the 0-1 loss, Bayes classifier is\n",
    "\n",
    "$$ \\arg \\min_f R(f) $$\n",
    "\n",
    "which is given by\n",
    "\n",
    "$$ f(x) = \\arg \\max_{z \\in Y} p(z |x) $$\n",
    "\n",
    "Comments:\n",
    "* Bayes classifier relies on the knowledge of the true density (of the classes and also the prior probability for each class).\n",
    "* Bayes classifier is the best possible classifier, but best is not necessarily perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.2. Getting posterior probability via Bayes theorem\n",
    "\n",
    "Consider the following toy example. We know the true probability density $p(x)$ as well as the priors $p(1)$ and $p(2)$, where $p(x, 1) = p(x|1) * p(1)$. The posterior probability $p(*|x)$ can be computed in terms of the prior and class density normalized by the density:\n",
    "\n",
    "<img src=\"img/bayes-theorem.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- Class density, e.g. $p(x|1)$, is also called likelihood.\n",
    "- Class probability, e.g. $p(1)$, is also called prior probability.\n",
    "- Probability density, $p(x)$, is also called evidence.\n",
    "\n",
    "In practice, all terms in the RHS can be estimated from the data, e.g. kernel density estimate on the red points to get $p(x|1)$. For the 0-1-loss discussed above, the rule of Bayes classifier is to predict the class with the largest posterior probability $p(.|x)$. The **Bayes decision boundary (in green)** is the set for which the posterior probability for class 1 equals the one for class 2, namely $p(1|x) = p(2|x) = 0.5$. However, note that even the Bayes classifier is not perfect, because there are observations which are misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.3 Quadratic Discriminant Analysis\n",
    "\n",
    "In ML, one typically makes distinction between generative vs discriminative classifiers:\n",
    "- Generative classifiers estimate class density, prior, and evidence (i.e. terms on the RHS). Example is Quadratic Discriminant Analysis.\n",
    "- Discriminative classifiers directly estimate posterior probability. Examples are k-NN, decision tree, random forest, etc.\n",
    "\n",
    "Although kernel density estimate can be used to approximate the class density, the data might have too few points and too many dimensions that make such kernel density estimate unreliable. In **quadratic discriminant analysis (QDA)**, we approximate each class in the training data by a single Gaussian (estimate the mean and covariance matrix). Then we apply Bayes theorem to compute the posterior probability. Note that we also need to estimate the prior (can be easily done by counting # of classes). The shape of the decision boundary can be found via Bayes Theorem as follows.\n",
    "\n",
    "$$\\begin{align*} p(1|x) & = p(2|x) \\\\\n",
    "    \\frac{p(x|1) p(1)}{p(x)} & = \\frac{p(x|2) p(2)}{p(x)} \\\\\n",
    "    c_1 \\exp[\\frac{-1}{2} (x - \\mu_1)^T \\Sigma_1^{-1} (x - \\mu_1)] p(1) & = c_2 \\exp[\\frac{-1}{2}(x - \\mu_2)^T \\Sigma_2^{-1} (x - \\mu_2)] p(2) \\\\\n",
    "    \\ln\\frac{c_1 p_1}{c_2 p_2} - \\frac{1}{2} (x - \\mu_1)^T \\Sigma_1^{-1} (x - \\mu_1) + \\frac{1}{2} (x - \\mu_2)^T \\Sigma_2^{-1} (x - \\mu_2) & = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Now, the first term is a scalar constant, and therefore the equation is quadratic in $x$. This suggests that the decision boundaries of QDA are **quadrics**, which is an umbrella term for ellipse, hyperbola, parabola, and parallel lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3.4 Multivariate Normal\n",
    "\n",
    "A multivariate Gaussian has two parameters: mean and covariance, where the covariance is defined as\n",
    "\n",
    "$$ \\begin{split}\n",
    "Cov(X) & := \\mathbb{E}[(X - \\mathbb{E}[X]) \\, (X - \\mathbb{E}[X])^T] \\\\\n",
    "    & = \\mathbb{E}[XX^T - X \\mathbb{E}[X^T] - E[X] X^T + E[X] E[X^T]] \\\\\n",
    "    & = \\mathbb{E}[XX^T] - \\mathbb{E}[X] \\mathbb{E}[X^T]\n",
    "    \\end{split}\n",
    "$$\n",
    "\n",
    "- $X$ is a vector $p \\times 1$ of random variables\n",
    "- $\\mathbb{E}[\\mathbb{E}[X]] = \\mathbb{E}[X]$ because expectation value of a random variable is a constant, and expectation value of a constant is the constant itself.\n",
    "- It follows that covariance of an affinely-transposed random variable is $Cov(AX) = A Cov(X) A^T$ for some matrix A.\n",
    "- The covariance matrix has dimension $p \\times p$.\n",
    "\n",
    "Empirical estimate of covariance is given by\n",
    "\n",
    "$$ \\frac{1}{n-1} S = \\frac{1}{n-1}XCC^T X^T = \\frac{1}{n-1}XCX^T$$\n",
    "\n",
    "where S is the scatter matrix and C is the centering matrixï¼Œwith $CC^T = C$. Once the data is centered once, nothing happens if we center it again $C = I - \\frac{1}{n} 1 * 1^T$; here $1$ is the column vector of ones. The isocountours of a multivariate Gaussian are shown below for negative cross-correlation (left), stronger negative cross-correlation, and positive cross-correlation with higher spread at the 2nd dimension.\n",
    "\n",
    "<img src=\"img/covariance.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "The diagonal elements has the variance of each dimension. The off-diagonal elements indicate how much linear association is between random variable along different dimensions. The **normal distribution** is defined as\n",
    "\n",
    "$$p(x) = \\frac{1}{(2\\pi)^{p/2} |\\Sigma|^{1/2}} \\exp[-\\frac{1}{2}(x - \\mu)^T \\Sigma^{-1} (x - \\mu)]$$\n",
    "\n",
    "Points worth noting:\n",
    "- The inverse covariance matrix $\\Sigma^{-1}$ is also called the precision matrix: the larger the covariance/spread, the \"better\" the precision is.\n",
    "- $\\mu$ is the mean vector of the data\n",
    "- marginal of a normal distribution is normal\n",
    "- conditional of a normal distribution is normal\n",
    "- normal marginal doesn't necessarily give normal joint distribution\n",
    "\n",
    "See https://juanitorduz.github.io/multivariate_normal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
